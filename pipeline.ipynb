{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.preproc import load_data, split_df, get_xxyy\n",
    "from scripts.train import train_grid, predict_val\n",
    "from scripts.submit import get_submitable\n",
    "train_cols = ['precipitation_amt_mm', 'weekofyear_sin', 'weekofyear_cos']\n",
    "target_col = 'total_cases'\n",
    "test_size = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Preprocessing\n",
    "\n",
    "## 1.1 Train features and labes are merged, both train and test DFs are devided by cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sj, train_iq, test_sj, test_iq = load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.line(train_sj, x='date', y=[\"precipitation_amt_mm\", 'station_avg_temp_c', 'total_cases', 'weekofyear_sin', 'weekofyear_cos'], title='San Juan')\n",
    "# fig.show()\n",
    "# fig = px.line(train_iq, x='date', y=[\"precipitation_amt_mm\", 'station_avg_temp_c', 'total_cases', 'weekofyear_sin', 'weekofyear_cos'], title='Iquitos')\n",
    "# fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Spliting into training and validation sets\n",
    "\n",
    "I suggest that at the end of preprocessing for either city we get **one** dictionary with **four** dataframes: X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 936, validation size: 0\n",
      "Train size: 520, validation size: 0\n"
     ]
    }
   ],
   "source": [
    "xxyy_sj = get_xxyy(train_sj, test_size, train_cols, target_col)\n",
    "xxyy_iq = get_xxyy(train_iq, test_size, train_cols, target_col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of training we need:\n",
    "1. a model compatible with scikit-learn api\n",
    "2. (maybe???) an encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "cv = TimeSeriesSplit(5)\n",
    "scoring = 'neg_mean_absolute_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "estimator = RandomForestRegressor()\n",
    "params = dict(\n",
    "\tn_estimators = [3000, 2500, 2000],\n",
    "\tmax_depth = [3, 4, 5],\n",
    "\t# eta = [0.3, 0.1, 0.01],\n",
    "\t# subsample = [0.3, 0.5, 0.8, 1],\n",
    "\t# colsample_bytree = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sj = train_grid(xxyy_sj, estimator, params, scoring)\n",
    "model_iq = train_grid(xxyy_iq, estimator, params, scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_max_depth', 'param_n_estimators', 'params', 'split0_test_score',\n",
       "       'split1_test_score', 'split2_test_score', 'split3_test_score',\n",
       "       'split4_test_score', 'mean_test_score', 'std_test_score',\n",
       "       'rank_test_score', 'split0_train_score', 'split1_train_score',\n",
       "       'split2_train_score', 'split3_train_score', 'split4_train_score',\n",
       "       'mean_train_score', 'std_train_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model_sj.cv_results_).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "San Jose\n",
      "  param_max_depth param_n_estimators  mean_train_score\n",
      "0               3               3000        -24.043547\n",
      "1               3               2500        -24.045690\n",
      "4               4               2500        -23.018336\n",
      "2               3               2000        -24.056120\n",
      "5               4               2000        -23.028105\n",
      "3               4               3000        -23.044900\n",
      "6               5               3000        -21.734006\n",
      "8               5               2000        -21.736993\n",
      "7               5               2500        -21.743137\n",
      "\n",
      "Iquitos\n",
      "  param_max_depth param_n_estimators  mean_train_score\n",
      "2               3               2000         -5.892714\n",
      "0               3               3000         -5.895742\n",
      "1               3               2500         -5.899944\n",
      "5               4               2000         -5.544294\n",
      "4               4               2500         -5.540441\n",
      "3               4               3000         -5.544559\n",
      "7               5               2500         -5.083082\n",
      "6               5               3000         -5.083995\n",
      "8               5               2000         -5.083663\n"
     ]
    }
   ],
   "source": [
    "print('San Jose')\n",
    "print(pd.DataFrame(model_sj.cv_results_)\n",
    "\t.sort_values(by='rank_test_score')[[\n",
    "\t\t'param_max_depth', 'param_n_estimators', 'mean_train_score']])\n",
    "print()\n",
    "print('Iquitos')\n",
    "print(pd.DataFrame(model_iq.cv_results_)\n",
    "\t.sort_values(by='rank_test_score')[[\n",
    "\t\t'param_max_depth', 'param_n_estimators', 'mean_train_score']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Predict for test features and format for submition\n",
    "\n",
    "For that we need:\n",
    "1. [from precrocessing] - (list of) test DFs\n",
    "2. [from training]      - (list of) models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_submitable([test_sj, test_iq], [model_sj, model_iq], train_cols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4707a85cf9eb5c57a7057e16345ceed3881708617324b4818fac2dac5a5b689f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
