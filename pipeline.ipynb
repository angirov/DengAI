{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.preproc import load_data, split_df, get_xxyy\n",
    "from scripts.train import train_rfr, predict_val\n",
    "from scripts.submit import get_submitable\n",
    "train_cols = ['precipitation_amt_mm', 'weekofyear_sin', 'weekofyear_cos']\n",
    "target_col = 'total_cases'\n",
    "test_size = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Preprocessing\n",
    "\n",
    "## 1.1 Train features and labes are merged, both train and test DFs are devided by cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sj, train_iq, test_sj, test_iq = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sj.head().T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.line(train_sj, x='date', y=[\"precipitation_amt_mm\", 'station_avg_temp_c', 'total_cases', 'weekofyear_sin', 'weekofyear_cos'], title='San Juan')\n",
    "# fig.show()\n",
    "# fig = px.line(train_iq, x='date', y=[\"precipitation_amt_mm\", 'station_avg_temp_c', 'total_cases', 'weekofyear_sin', 'weekofyear_cos'], title='Iquitos')\n",
    "# fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Spliting into training and validation sets\n",
    "\n",
    "I suggest that at the end of preprocessing for either city we get **one** dictionary with **four** dataframes: X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 936, validation size: 0\n",
      "Train size: 520, validation size: 0\n"
     ]
    }
   ],
   "source": [
    "xxyy_sj = get_xxyy(train_sj, test_size, train_cols, target_col)\n",
    "xxyy_iq = get_xxyy(train_iq, test_size, train_cols, target_col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of training we need:\n",
    "1. a model compatible with scikit-learn api\n",
    "2. (maybe???) an encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "cv = TimeSeriesSplit(5)\n",
    "scoring = 'neg_mean_absolute_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "estimator = RandomForestRegressor()\n",
    "params = dict(\n",
    "\tn_estimators=[700, 1000, 1500, 2000],\n",
    "\tmax_depth=[2, 3, 4, 5, 10]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "# https://machinelearningmastery.com/xgboost-for-regression/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestRegressor()\n",
    "params = dict(\n",
    "\tn_estimators = [2500, 2000, 1500],\n",
    "\tmax_depth = [3, 4, 5],\n",
    "\t# eta = [0.3, 0.1, 0.01],\n",
    "\t# subsample = [0.3, 0.5, 0.8, 1],\n",
    "\t# colsample_bytree = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sj = train_grid(xxyy_sj, estimator, params, scoring)\n",
    "model_iq = train_grid(xxyy_iq, estimator, params, scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 3, 'n_estimators': 2000},\n",
       " {'max_depth': 3, 'n_estimators': 2000})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sj.best_params_, model_iq.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_sj = predict_val(model_sj, xxyy_sj['X_val'], xxyy_sj['y_val'])\n",
    "# y_pred_iq = predict_val(model_iq, xxyy_iq['X_val'], xxyy_iq['y_val'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Predict for test features and format for submition\n",
    "\n",
    "For that we need:\n",
    "1. [from precrocessing] - (list of) test DFs\n",
    "2. [from training]      - (list of) models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_submitable([test_sj, test_iq], [model_sj, model_iq], train_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target['date'] = pd.to_datetime(target['year'].astype('str') + '-' + target['weekofyear'].astype('str') + '-0', format='%Y-%W-%w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4707a85cf9eb5c57a7057e16345ceed3881708617324b4818fac2dac5a5b689f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
